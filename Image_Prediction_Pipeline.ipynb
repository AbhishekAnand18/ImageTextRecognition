{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Text Recognition Model Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Pipeline has 2 Functions for Output Prediction:\n",
    "1. **Single Image Prediction:** Takes a single input Image and Gives the Final Text Label as output\n",
    "2. **Multiple Image Prediction:** Takes list of Image path names of images to be predicted and prints Actual Text Label and its corresponding Predicted Output Text Label for each Image present in the Folder Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os \n",
    "import cv2\n",
    "from datetime import datetime\n",
    "import keras\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import itertools\n",
    "from keras import backend as K\n",
    "from keras.layers import Input, Conv2D, MaxPool2D, Dense,MaxPooling2D,Bidirectional\n",
    "from keras.layers import AveragePooling2D, Flatten, Activation\n",
    "from keras.layers import BatchNormalization, Dropout\n",
    "from keras.layers import Concatenate, Add, Multiply, Lambda\n",
    "from keras.layers import UpSampling2D, Reshape\n",
    "from keras.layers.merge import add,concatenate\n",
    "from keras.layers import Reshape\n",
    "from keras.models import Model\n",
    "from keras.layers.recurrent import LSTM,GRU\n",
    "import tensorflow as tf\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sampled_data_100.csv** file contains 100 Images sampled from Synth Text Test Data for Pipeline Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data=pd.read_csv('Sampled_data_100.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 2)\n"
     ]
    }
   ],
   "source": [
    "test_data.drop(['Unnamed: 0'],axis=1,inplace=True)\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageName</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Test_data/501_nonadhesive.jpg</td>\n",
       "      <td>NONADHESIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Test_data/502_Aglitter.jpg</td>\n",
       "      <td>AGLITTER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Test_data/503_azania.jpg</td>\n",
       "      <td>AZANIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Test_data/504_Pliocenes.jpg</td>\n",
       "      <td>PLIOCENES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Test_data/505_Cozenage.jpg</td>\n",
       "      <td>COZENAGE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       ImageName       Labels\n",
       "0  Test_data/501_nonadhesive.jpg  NONADHESIVE\n",
       "1     Test_data/502_Aglitter.jpg     AGLITTER\n",
       "2       Test_data/503_azania.jpg       AZANIA\n",
       "3    Test_data/504_Pliocenes.jpg    PLIOCENES\n",
       "4     Test_data/505_Cozenage.jpg     COZENAGE"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Letters present in the Label Text\n",
    "letters= '0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Integer Labels to Text Label Converter**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converts a list of integers to corresponding characters and combines them as a string "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def words_from_labels(labels):\n",
    "    \"\"\"\n",
    "    converts the list of encoded integer labels to word strings like eg. [12,10,29] returns CAT \n",
    "    \"\"\"\n",
    "    txt=[]\n",
    "    for ele in labels:\n",
    "        if ele == len(letters): # CTC blank space\n",
    "            txt.append(\"\")\n",
    "        else:\n",
    "            #print(letters[ele])\n",
    "            txt.append(letters[ele])\n",
    "    return \"\".join(txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Best Path Decoding**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Function Takes the final 48x37 output matrix from the model, and takes the argmax of the matrix across each column (which returns a value between 0 to 36 (ctc_blank) both included). The outputs are then merged for repeated values and gives a list of integers. The Final output integers is then converted to final output string text and it is returned by the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://keras.io/examples/image_ocr/\n",
    "#https://github.com/qjadud1994/CRNN-Keras\n",
    "def decode_label(out):\n",
    "    \"\"\"\n",
    "    Takes the predicted ouput matrix from the Model and returns the output text for the image\n",
    "    \"\"\"\n",
    "    # out : (1, 48, 37)\n",
    "    out_best = list(np.argmax(out[0,2:], axis=1))\n",
    "\n",
    "    out_best = [k for k, g in itertools.groupby(out_best)]  # remove overlap value\n",
    "\n",
    "    outstr=words_from_labels(out_best)\n",
    "    return outstr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#image height\n",
    "img_h=32\n",
    "#image width\n",
    "img_w=170\n",
    "#image Channels\n",
    "img_c=1\n",
    "# classes for softmax with number of letters +1 for blank space in ctc\n",
    "num_classes=len(letters)+1\n",
    "batch_size=64\n",
    "max_length=15 # considering max length of ground truths labels to be 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_create(drop_out_rate=0.35):\n",
    "    \"\"\"\n",
    "    Builds the model which takes input as images which is used for prediction and returns the Output Matrix \n",
    "    of of dimesnions 48x37 where 48 is the number of time-steps of RNN and 37 is the length of letters \n",
    "    + 1 character for ctc blank\n",
    "    \"\"\"\n",
    "    \n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        input_shape = (1, img_w, img_h)\n",
    "    else:\n",
    "        input_shape = (img_w, img_h, 1)\n",
    "       \n",
    "    model_input=Input(shape=input_shape,name='img_input',dtype='float32')\n",
    "\n",
    "    # Convolution layer \n",
    "    model = Conv2D(64, (3, 3), padding='same', name='conv1', kernel_initializer='he_normal')(model_input) \n",
    "    model = BatchNormalization()(model)\n",
    "    model = Activation('relu')(model)\n",
    "    model = MaxPooling2D(pool_size=(2, 2), name='max1')(model) \n",
    "\n",
    "    model = Conv2D(128, (3, 3), padding='same', name='conv2', kernel_initializer='he_normal')(model) \n",
    "    model = BatchNormalization()(model)\n",
    "    model = Activation('relu')(model)\n",
    "    model = MaxPooling2D(pool_size=(2, 2), name='max2')(model) \n",
    "\n",
    "    model = Conv2D(256, (3, 3), padding='same', name='conv3', kernel_initializer='he_normal')(model) \n",
    "    model = BatchNormalization()(model)\n",
    "    model = Activation('relu')(model)\n",
    "    model = Conv2D(256, (3, 3), padding='same', name='conv4', kernel_initializer='he_normal')(model)\n",
    "    model=Dropout(drop_out_rate)(model)\n",
    "    model = BatchNormalization()(model)\n",
    "    model = Activation('relu')(model)\n",
    "    model = MaxPooling2D(pool_size=(1, 2), name='max3')(model)  \n",
    "\n",
    "    model = Conv2D(512, (3, 3), padding='same', name='conv5', kernel_initializer='he_normal')(model) \n",
    "    model = BatchNormalization()(model)\n",
    "    model = Activation('relu')(model)\n",
    "    model = Conv2D(512, (3, 3), padding='same', name='conv6')(model)\n",
    "    model=Dropout(drop_out_rate)(model)\n",
    "    model = BatchNormalization()(model)\n",
    "    model = Activation('relu')(model)\n",
    "    model = MaxPooling2D(pool_size=(1, 2), name='max4')(model) \n",
    "\n",
    "    model = Conv2D(512, (2, 2), padding='same', kernel_initializer='he_normal', name='con7')(model)\n",
    "    model=Dropout(0.25)(model)\n",
    "    model = BatchNormalization()(model)\n",
    "    model = Activation('relu')(model)    \n",
    "\n",
    "    # CNN to RNN\n",
    "    model = Reshape(target_shape=((42, 1024)), name='reshape')(model)  \n",
    "    model = Dense(64, activation='relu', kernel_initializer='he_normal', name='dense1')(model)  \n",
    "\n",
    "    # RNN layer\n",
    "    model=Bidirectional(LSTM(256, return_sequences=True, kernel_initializer='he_normal'), merge_mode='sum')(model)\n",
    "    model=Bidirectional(LSTM(256, return_sequences=True, kernel_initializer='he_normal'), merge_mode='concat')(model)\n",
    "\n",
    "    # transforms RNN output to character activations:\n",
    "    model = Dense(num_classes, kernel_initializer='he_normal',name='dense2')(model) \n",
    "    y_pred = Activation('softmax', name='softmax')(model)\n",
    "\n",
    "    return Model(inputs=[model_input], outputs=y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Image Prediction Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_data_single_image_Prediction(model,test_img_path):\n",
    "    \"\"\"\n",
    "    Takes the best model, test data image paths, test data groud truth labels and pre-processes the input image to \n",
    "    appropriate format for the model prediction, takes the predicted output matrix and uses best path decoding to \n",
    "    generate predicted text and prints the Predicted Text Label, Time Taken for Computation\n",
    "    \"\"\"\n",
    "    start=datetime.now()\n",
    "    \n",
    "    test_img=cv2.imread(test_img_path)\n",
    "    test_img_resized=cv2.resize(test_img,(170,32))\n",
    "    test_image=test_img_resized[:,:,1]\n",
    "    test_image=test_image.T \n",
    "    test_image=np.expand_dims(test_image,axis=-1)\n",
    "    test_image=np.expand_dims(test_image, axis=0)\n",
    "    test_image=test_image/255\n",
    "    model_output=model.predict(test_image)\n",
    "    predicted_output=decode_label(model_output)\n",
    "    print(\"Predicted Text in the Image: \", predicted_output)\n",
    "    print(\"Time Taken for Processing: \",datetime.now()-start)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_data_multiple_image_Prediction(model,test_img_names,test_labels,total):\n",
    "    \"\"\"\n",
    "    Takes the best model, test data image paths, test data groud truth labels and pre-processes the input image to \n",
    "    appropriate format for the model prediction, takes the predicted output matrix and uses best path decoding to \n",
    "    generate predicted text and compares with ground truth text for the input and ouputs the final accuracy,\n",
    "    letter accuracy and  letter count across the entire test set of images\n",
    "    \"\"\"\n",
    "    start=datetime.now()\n",
    "    accuracy=0\n",
    "    letter_acc=0\n",
    "    letter_cnt=0\n",
    "    count=0\n",
    "    for i in range(len(test_labels)):\n",
    "        test_img=cv2.imread(test_img_names[i])\n",
    "        test_img_resized=cv2.resize(test_img,(170,32))\n",
    "        test_image=test_img_resized[:,:,1]\n",
    "        test_image=test_image.T\n",
    "        test_image=np.expand_dims(test_image,axis=-1)\n",
    "        test_image=np.expand_dims(test_image, axis=0)\n",
    "        test_image=test_image/255\n",
    "        model_output=model.predict(test_image)\n",
    "        predicted_output=decode_label(model_output)\n",
    "        actual_output=test_labels[i]\n",
    "        count+=1\n",
    "        for j in range(min(len(predicted_output),len(actual_output))):\n",
    "            if predicted_output[j]==actual_output[j]:\n",
    "                letter_acc+=1\n",
    "        letter_cnt+=max(len(predicted_output),len(actual_output))\n",
    "        if actual_output==predicted_output:\n",
    "            accuracy+=1\n",
    "        print(\"-\"*80)\n",
    "        print(\"Actual Text: \",actual_output,\"   Predicted Text: \",predicted_output)\n",
    "    print(\"=\"*80)\n",
    "    print(\"Model Output Accuracy: \",(accuracy/total)*100, \" %\")\n",
    "    print(\"Model Output Letter Accuracy: \",(letter_acc/letter_cnt)*100, \" %\")\n",
    "    print(\"Time Taken for Processing: \",datetime.now()-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Loading Best Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ASUS\\Anaconda3\\envs\\dl_env\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\ASUS\\Anaconda3\\envs\\dl_env\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "model=model_create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "img_input (InputLayer)       (None, 170, 32, 1)        0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 170, 32, 64)       640       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 170, 32, 64)       256       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 170, 32, 64)       0         \n",
      "_________________________________________________________________\n",
      "max1 (MaxPooling2D)          (None, 85, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2 (Conv2D)               (None, 85, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 85, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 85, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "max2 (MaxPooling2D)          (None, 42, 8, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv3 (Conv2D)               (None, 42, 8, 256)        295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 42, 8, 256)        1024      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 42, 8, 256)        0         \n",
      "_________________________________________________________________\n",
      "conv4 (Conv2D)               (None, 42, 8, 256)        590080    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 42, 8, 256)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 42, 8, 256)        1024      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 42, 8, 256)        0         \n",
      "_________________________________________________________________\n",
      "max3 (MaxPooling2D)          (None, 42, 4, 256)        0         \n",
      "_________________________________________________________________\n",
      "conv5 (Conv2D)               (None, 42, 4, 512)        1180160   \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 42, 4, 512)        2048      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 42, 4, 512)        0         \n",
      "_________________________________________________________________\n",
      "conv6 (Conv2D)               (None, 42, 4, 512)        2359808   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 42, 4, 512)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 42, 4, 512)        2048      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 42, 4, 512)        0         \n",
      "_________________________________________________________________\n",
      "max4 (MaxPooling2D)          (None, 42, 2, 512)        0         \n",
      "_________________________________________________________________\n",
      "con7 (Conv2D)                (None, 42, 2, 512)        1049088   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 42, 2, 512)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 42, 2, 512)        2048      \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 42, 2, 512)        0         \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 42, 1024)          0         \n",
      "_________________________________________________________________\n",
      "dense1 (Dense)               (None, 42, 64)            65600     \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 42, 256)           657408    \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 42, 512)           1050624   \n",
      "_________________________________________________________________\n",
      "dense2 (Dense)               (None, 42, 37)            18981     \n",
      "_________________________________________________________________\n",
      "softmax (Activation)         (None, 42, 37)            0         \n",
      "=================================================================\n",
      "Total params: 7,350,373\n",
      "Trainable params: 7,345,893\n",
      "Non-trainable params: 4,480\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Best Weights for the Model are stored in BestLSTMModelWeights Folder, loading the stored best weights for Model 1 for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('Final_LSTM_Model_Best_Weights/Best_Img_recog_LSTM_Adam_model_run_weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Single Image Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image_1='Test_Data/3_Chronographs.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(test_image_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Text in the Image:  CHRONOGRAPHS\n",
      "Time Taken for Processing:  0:00:03.264209\n"
     ]
    }
   ],
   "source": [
    "test_data_single_image_Prediction(model,test_image_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image_2='Test_Data/36_goldmine.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(test_image_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Text in the Image:  GOLDMINE\n",
      "Time Taken for Processing:  0:00:00.083438\n"
     ]
    }
   ],
   "source": [
    "test_data_single_image_Prediction(model,test_image_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image_3='Test_Data/48_SCHOOLBOY.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(test_image_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Text in the Image:  SCHOOLBOY\n",
      "Time Taken for Processing:  0:00:00.066124\n"
     ]
    }
   ],
   "source": [
    "test_data_single_image_Prediction(model,test_image_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Multiple Image Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img_paths=test_data['ImageName'].values\n",
    "test_img_labels=test_data['Labels'].values\n",
    "total=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Actual Text:  NONADHESIVE    Predicted Text:  NONADHESIVE\n",
      "--------------------------------------------------------------------------------\n",
      "Actual Text:  AGLITTER    Predicted Text:  AGLITTER\n",
      "--------------------------------------------------------------------------------\n",
      "Actual Text:  AZANIA    Predicted Text:  AZANIA\n",
      "--------------------------------------------------------------------------------\n",
      "Actual Text:  PLIOCENES    Predicted Text:  PLIOCENES\n",
      "--------------------------------------------------------------------------------\n",
      "Actual Text:  COZENAGE    Predicted Text:  COZENOGE\n",
      "--------------------------------------------------------------------------------\n",
      "Actual Text:  LIEFER    Predicted Text:  LIEFER\n",
      "--------------------------------------------------------------------------------\n",
      "Actual Text:  OUTBOXES    Predicted Text:  OUTBOXES\n",
      "--------------------------------------------------------------------------------\n",
      "Actual Text:  KEYPADS    Predicted Text:  KEYPADS\n",
      "--------------------------------------------------------------------------------\n",
      "Actual Text:  BREWSTER    Predicted Text:  BREWSTER\n",
      "--------------------------------------------------------------------------------\n",
      "Actual Text:  MOLLUSK    Predicted Text:  MOLLUSK\n",
      "--------------------------------------------------------------------------------\n",
      "Actual Text:  LAVISHNESS    Predicted Text:  LAVISHNESS\n",
      "--------------------------------------------------------------------------------\n",
      "Actual Text:  POACHERS    Predicted Text:  POACHERS\n",
      "--------------------------------------------------------------------------------\n",
      "Actual Text:  POSTMISTRESS    Predicted Text:  POSTMISTRESS\n",
      "--------------------------------------------------------------------------------\n",
      "Actual Text:  TEXTURE    Predicted Text:  TEXTURE\n",
      "--------------------------------------------------------------------------------\n",
      "Actual Text:  AVENGING    Predicted Text:  AVENGING\n",
      "--------------------------------------------------------------------------------\n",
      "Actual Text:  SCUBAED    Predicted Text:  SCUBAED\n",
      "--------------------------------------------------------------------------------\n",
      "Actual Text:  MINDLESSNESS    Predicted Text:  MNDESSNESS\n",
      "--------------------------------------------------------------------------------\n",
      "Actual Text:  DELINEATE    Predicted Text:  DELINEATE\n",
      "--------------------------------------------------------------------------------\n",
      "Actual Text:  SUMMERIER    Predicted Text:  SUMMERIER\n",
      "--------------------------------------------------------------------------------\n",
      "Actual Text:  CLARA    Predicted Text:  CLARA\n",
      "--------------------------------------------------------------------------------\n",
      "Actual Text:  TARRY    Predicted Text:  FARRY\n",
      "--------------------------------------------------------------------------------\n",
      "Actual Text:  WEATHERIZES    Predicted Text:  WEATHERIZES\n",
      "--------------------------------------------------------------------------------\n",
      "Actual Text:  CIRCUMVENT    Predicted Text:  CIRCUMVENT\n",
      "--------------------------------------------------------------------------------\n",
      "Actual Text:  GOBBLER    Predicted Text:  GOBBLER\n",
      "--------------------------------------------------------------------------------\n",
      "Actual Text:  BISMUTH    Predicted Text:  BISMUTH\n",
      "--------------------------------------------------------------------------------\n",
      "Actual Text:  MOMENTARILY    Predicted Text:  MOMENTARILY\n",
      "--------------------------------------------------------------------------------\n",
      "Actual Text:  ATTENDING    Predicted Text:  ATTENDING\n",
      "--------------------------------------------------------------------------------\n",
      "Actual Text:  EARPHONES    Predicted Text:  EARRIAIMS\n",
      "--------------------------------------------------------------------------------\n",
      "Actual Text:  ABSENTLY    Predicted Text:  ABSENTLY\n",
      "--------------------------------------------------------------------------------\n",
      "Actual Text:  AHOY    Predicted Text:  AHOY\n",
      "--------------------------------------------------------------------------------\n",
      "Actual Text:  CATSUIT    Predicted Text:  CATSUIT\n",
      "--------------------------------------------------------------------------------\n",
      "Actual Text:  STRAGGLING    Predicted Text:  STRAGGLING\n",
      "--------------------------------------------------------------------------------\n",
      "Actual Text:  BUMPIER    Predicted Text:  BUMPIER\n",
      "--------------------------------------------------------------------------------\n",
      "Actual Text:  INURING    Predicted Text:  INURING\n",
      "--------------------------------------------------------------------------------\n",
      "Actual Text:  UNPEOPLE    Predicted Text:  LNPEOPLE\n",
      "--------------------------------------------------------------------------------\n",
      "Actual Text:  FLANNEL    Predicted Text:  FLANNEL\n",
      "--------------------------------------------------------------------------------\n",
      "Actual Text:  ANNUITIES    Predicted Text:  ANNUITIES\n",
      "--------------------------------------------------------------------------------\n",
      "Actual Text:  TYREE    Predicted Text:  TYREE\n",
      "--------------------------------------------------------------------------------\n",
      "Actual Text:  UNCANNIEST    Predicted Text:  UNCANNIESS\n",
      "--------------------------------------------------------------------------------\n",
      "Actual Text:  UNDECEIVING    Predicted Text:  UNSEEERROS\n",
      "--------------------------------------------------------------------------------\n",
      "Actual Text:  HOUSEBROKEN    Predicted Text:  HOUSEBROKEN\n",
      "--------------------------------------------------------------------------------\n",
      "Actual Text:  POLICEWOMAN    Predicted Text:  COLEEWORMON\n",
      "--------------------------------------------------------------------------------\n",
      "Actual Text:  GRIT    Predicted Text:  GRIT\n",
      "--------------------------------------------------------------------------------\n",
      "Actual Text:  SHOESTRINGS    Predicted Text:  SHOESTRINGS\n",
      "--------------------------------------------------------------------------------\n",
      "Actual Text:  CHISINAU    Predicted Text:  CHISINAL\n",
      "--------------------------------------------------------------------------------\n",
      "Actual Text:  HALFPENNIES    Predicted Text:  HALFPENNIES\n",
      "--------------------------------------------------------------------------------\n",
      "Actual Text:  NEWSCAST    Predicted Text:  NSWCCAST\n",
      "--------------------------------------------------------------------------------\n",
      "Actual Text:  RAILED    Predicted Text:  RAILED\n",
      "--------------------------------------------------------------------------------\n",
      "Actual Text:  PHOTOGRAPHER    Predicted Text:  PHOTOGRAPHER\n",
      "--------------------------------------------------------------------------------\n",
      "Actual Text:  REPORTEDLY    Predicted Text:  REPONTEDLY\n",
      "--------------------------------------------------------------------------------\n",
      "Actual Text:  SLAGS    Predicted Text:  SLIGS\n",
      "--------------------------------------------------------------------------------\n",
      "Actual Text:  RAVAGE    Predicted Text:  RAVAGE\n",
      "--------------------------------------------------------------------------------\n",
      "Actual Text:  PLAINTIVELY    Predicted Text:  PLAINTIVELY\n",
      "--------------------------------------------------------------------------------\n",
      "Actual Text:  YAMMER    Predicted Text:  YAMMER\n",
      "--------------------------------------------------------------------------------\n",
      "Actual Text:  RUFFIANS    Predicted Text:  RUFFIANS\n",
      "--------------------------------------------------------------------------------\n",
      "Actual Text:  VICARS    Predicted Text:  VICARS\n",
      "--------------------------------------------------------------------------------\n",
      "Actual Text:  ACYCLOVIR    Predicted Text:  ACYCLOVIR\n",
      "--------------------------------------------------------------------------------\n",
      "Actual Text:  COMBS    Predicted Text:  COMBS\n",
      "--------------------------------------------------------------------------------\n",
      "Actual Text:  NOELS    Predicted Text:  NOELS\n",
      "--------------------------------------------------------------------------------\n",
      "Actual Text:  UNBALANCE    Predicted Text:  UNBALANCE\n",
      "--------------------------------------------------------------------------------\n",
      "Actual Text:  INVENT    Predicted Text:  INVENT\n",
      "--------------------------------------------------------------------------------\n",
      "Actual Text:  CARROTY    Predicted Text:  CARROTY\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Actual Text:  INDISSOLUBLE    Predicted Text:  INDISSOLUBLE\n",
      "--------------------------------------------------------------------------------\n",
      "Actual Text:  WIST    Predicted Text:  WIST\n",
      "--------------------------------------------------------------------------------\n",
      "Actual Text:  BACKBITER    Predicted Text:  BACKBITER\n",
      "--------------------------------------------------------------------------------\n",
      "Actual Text:  FITMENT    Predicted Text:  FITMENT\n",
      "--------------------------------------------------------------------------------\n",
      "Actual Text:  TRAMMEL    Predicted Text:  TRAMMEL\n",
      "--------------------------------------------------------------------------------\n",
      "Actual Text:  RADIATE    Predicted Text:  RADIATE\n",
      "--------------------------------------------------------------------------------\n",
      "Actual Text:  SKEPTICAL    Predicted Text:  SKEPTICAL\n",
      "--------------------------------------------------------------------------------\n",
      "Actual Text:  FINKING    Predicted Text:  FINKING\n",
      "--------------------------------------------------------------------------------\n",
      "Actual Text:  SEWER    Predicted Text:  SELWER\n",
      "--------------------------------------------------------------------------------\n",
      "Actual Text:  REPARABLE    Predicted Text:  REPARABLE\n",
      "--------------------------------------------------------------------------------\n",
      "Actual Text:  EXCEPTING    Predicted Text:  EXCEPTING\n",
      "--------------------------------------------------------------------------------\n",
      "Actual Text:  UNALIGNED    Predicted Text:  UNALIGNED\n",
      "--------------------------------------------------------------------------------\n",
      "Actual Text:  AFOOT    Predicted Text:  AFOOT\n",
      "--------------------------------------------------------------------------------\n",
      "Actual Text:  ARCHDUKES    Predicted Text:  ARCHDUKES\n",
      "--------------------------------------------------------------------------------\n",
      "Actual Text:  DOUSING    Predicted Text:  DOUSING\n",
      "--------------------------------------------------------------------------------\n",
      "Actual Text:  SEPARATIVE    Predicted Text:  SELANATIVE\n",
      "--------------------------------------------------------------------------------\n",
      "Actual Text:  RASCALS    Predicted Text:  RASCALS\n",
      "--------------------------------------------------------------------------------\n",
      "Actual Text:  WARRANTING    Predicted Text:  WARRANTING\n",
      "--------------------------------------------------------------------------------\n",
      "Actual Text:  SIGN    Predicted Text:  SIGN\n",
      "--------------------------------------------------------------------------------\n",
      "Actual Text:  OVERAGES    Predicted Text:  OVERAGES\n",
      "--------------------------------------------------------------------------------\n",
      "Actual Text:  SQUEAMISHLY    Predicted Text:  SQUEMMISHLY\n",
      "--------------------------------------------------------------------------------\n",
      "Actual Text:  JOUNCES    Predicted Text:  JOUNCES\n",
      "--------------------------------------------------------------------------------\n",
      "Actual Text:  AILING    Predicted Text:  AILING\n",
      "--------------------------------------------------------------------------------\n",
      "Actual Text:  TIPPETS    Predicted Text:  TIPPETS\n",
      "--------------------------------------------------------------------------------\n",
      "Actual Text:  LATENESS    Predicted Text:  ZATENESS\n",
      "--------------------------------------------------------------------------------\n",
      "Actual Text:  JUDICIOUSLY    Predicted Text:  JUDICIOUSLY\n",
      "--------------------------------------------------------------------------------\n",
      "Actual Text:  THRONGS    Predicted Text:  THRONGS\n",
      "--------------------------------------------------------------------------------\n",
      "Actual Text:  OUTDOES    Predicted Text:  CUTDOES\n",
      "--------------------------------------------------------------------------------\n",
      "Actual Text:  GOTHICS    Predicted Text:  GOTHICS\n",
      "--------------------------------------------------------------------------------\n",
      "Actual Text:  HURLS    Predicted Text:  HURLS\n",
      "--------------------------------------------------------------------------------\n",
      "Actual Text:  TRUED    Predicted Text:  TRUED\n",
      "--------------------------------------------------------------------------------\n",
      "Actual Text:  ASHING    Predicted Text:  ASHING\n",
      "--------------------------------------------------------------------------------\n",
      "Actual Text:  RELABELING    Predicted Text:  RELABELING\n",
      "--------------------------------------------------------------------------------\n",
      "Actual Text:  OBVIATED    Predicted Text:  OBVIATED\n",
      "--------------------------------------------------------------------------------\n",
      "Actual Text:  TRIPLET    Predicted Text:  TRIPLET\n",
      "--------------------------------------------------------------------------------\n",
      "Actual Text:  RIDERLESS    Predicted Text:  RIDERLESS\n",
      "--------------------------------------------------------------------------------\n",
      "Actual Text:  WHITENER    Predicted Text:  WHITENER\n",
      "--------------------------------------------------------------------------------\n",
      "Actual Text:  APARTMENT    Predicted Text:  APARTMENT\n",
      "================================================================================\n",
      "Model Output Accuracy:  83.0  %\n",
      "Model Output Letter Accuracy:  93.9622641509434  %\n",
      "Time Taken for Processing:  0:00:08.212124\n"
     ]
    }
   ],
   "source": [
    "test_data_multiple_image_Prediction(model,test_img_paths,test_img_labels,total)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
